{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6fcb6937",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1cd459cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(file_name: str, num_rows_to_read: [int] = None) -> list[float]:\n",
    "    \"\"\"\n",
    "    Reads a CSV file and returns a list of float values.\n",
    "\n",
    "    Args:\n",
    "        file_name (str): The name of the CSV file to read.\n",
    "        num_rows_to_read (int, optional): The number of rows to read from the CSV file. If not specified, reads all rows.\n",
    "\n",
    "    Returns:\n",
    "        List[float]: A list of float values from the CSV file.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    with open(file_name, 'r') as f:\n",
    "        lines = f.readlines()[1:]\n",
    "        for i, line in enumerate(lines):\n",
    "            if num_rows_to_read is not None and i >= num_rows_to_read:\n",
    "                break\n",
    "            row = float(line.strip())\n",
    "            data.append(row)\n",
    "    return data\n",
    "\n",
    "def calculate_rmse(original_data: list[float], imputed_data: list[float]) -> float:\n",
    "    \"\"\"\n",
    "    Calculates the Root Mean Square Error (RMSE) between two lists of float values.\n",
    "\n",
    "    Args:\n",
    "        original_data (List[float]): The list of original data values.\n",
    "        imputed_data (List[float]): The list of imputed data values.\n",
    "\n",
    "    Returns:\n",
    "        float: The RMSE between the original and imputed data.\n",
    "    \"\"\"\n",
    "    n = len(original_data)\n",
    "    squared_errors = [(original - imputed) ** 2 for original, imputed in zip(original_data, imputed_data)]\n",
    "    mean_squared_error = sum(squared_errors) / n\n",
    "    rmse = math.sqrt(mean_squared_error)\n",
    "    return rmse\n",
    "\n",
    "def calculate_mae(original_data: list[float], imputed_data: list[float]) -> float:\n",
    "    \"\"\"\n",
    "    Calculates the Mean Absolute Error (MAE) between two lists of float values.\n",
    "\n",
    "    Args:\n",
    "        original_data (List[float]): The list of original data values.\n",
    "        imputed_data (List[float]): The list of imputed data values.\n",
    "\n",
    "    Returns:\n",
    "        float: The MAE between the original and imputed data.\n",
    "    \"\"\"\n",
    "    n = len(original_data)\n",
    "    absolute_errors = [abs(original - imputed) for original, imputed in zip(original_data, imputed_data)]\n",
    "    mae = sum(absolute_errors) / n\n",
    "    return mae\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "92989e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def introduce_missingness(data: list[float], missingness_percentage: float) -> list[float]:\n",
    "    \"\"\"\n",
    "    Introduces missingness into a list of data.\n",
    "\n",
    "    Args:\n",
    "        data (List[float]): The list of data.\n",
    "        missingness_percentage (float): The percentage of missing values to introduce.\n",
    "\n",
    "    Returns:\n",
    "        List[float]: The list of data with missing values introduced.\n",
    "    \"\"\"\n",
    "    num_missing = int(len(data) * missingness_percentage / 100)\n",
    "    missing_indices = []\n",
    "\n",
    "    while len(missing_indices) < num_missing:\n",
    "        r = random.randint(0, len(data) - 1)\n",
    "        if r not in missing_indices:\n",
    "            missing_indices.append(r)\n",
    "\n",
    "    for i in missing_indices:\n",
    "        data[i] = 0\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "479afab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_average(data: list[float], window_size: int) -> list[float]:\n",
    "    \"\"\"\n",
    "    Calculates the moving average of a list of data.\n",
    "\n",
    "    Args:\n",
    "        data (List[float]): The input data.\n",
    "        window_size (int): The size of the moving window.\n",
    "\n",
    "    Returns:\n",
    "        List[float]: The moving average of the data.\n",
    "    \"\"\"\n",
    "    return [sum([x for x in data[i:i+window_size] if x != 0]) / window_size for i in range(len(data) - window_size + 1)]\n",
    "\n",
    "def standard_deviation(data: list[float], window_size: int) -> list[float]:\n",
    "    \"\"\"\n",
    "    Calculates the standard deviation within a moving window of data.\n",
    "\n",
    "    Args:\n",
    "        data (List[float]): The input data.\n",
    "        window_size (int): The size of the moving window.\n",
    "\n",
    "    Returns:\n",
    "        List[float]: The standard deviation within the moving window.\n",
    "    \"\"\"\n",
    "    avg = moving_average(data, window_size)\n",
    "    variance = [sum([(x - avg[i])**2 for x in data[i:i+window_size] if x != 0]) / window_size for i in range(len(data) - window_size + 1)]\n",
    "    return [var**0.5 for var in variance]\n",
    "\n",
    "def detect_outliers(data: list[float], window_size: int, z_thresh: float) -> list[int]:\n",
    "    \"\"\"\n",
    "    Detects outliers within a moving window of data based on a z-score threshold.\n",
    "\n",
    "    Args:\n",
    "        data (List[float]): The input data.\n",
    "        window_size (int): The size of the moving window.\n",
    "        z_thresh (float): The z-score threshold for outlier detection.\n",
    "\n",
    "    Returns:\n",
    "        List[int]: The indices of detected outliers.\n",
    "    \"\"\"\n",
    "    outliers = []\n",
    "    avg = moving_average(data, window_size)\n",
    "    std_dev = standard_deviation(data, window_size)\n",
    "    \n",
    "    for i in range(len(data) - window_size + 1):\n",
    "        if data[i + window_size - 1] != 0 and abs(data[i + window_size - 1] - avg[i]) > z_thresh * std_dev[i]:\n",
    "            outliers.append(i + window_size - 1)\n",
    "            data[i + window_size - 1] = 0\n",
    "    return outliers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "19c83316",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SLR_impute(data: list[[float, int]]) -> list[[float, int]]:\n",
    "    \"\"\"\n",
    "    Performs Simple Linear Regression (SLR) imputation to fill in missing values in a list of data.\n",
    "\n",
    "    Args:\n",
    "        data (List[Union[float, int]]): The input data with some missing values (0).\n",
    "\n",
    "    Returns:\n",
    "        List[Union[float, int]]: The data with missing values imputed using SLR.\n",
    "    \"\"\"\n",
    "    known_data = [(i, d) for i, d in enumerate(data) if d != 0]\n",
    "    missing_indices = [i for i, d in enumerate(data) if d == 0]\n",
    "\n",
    "    if not known_data or not missing_indices:\n",
    "        return data\n",
    "\n",
    "    x_known, y_known = zip(*known_data)\n",
    "\n",
    "    # Compute coefficients for linear regression\n",
    "    n = len(x_known)\n",
    "    m_x, m_y = sum(x_known) / n, sum(y_known) / n\n",
    "    ss_xy = sum(y_known[i] * x_known[i] for i in range(n)) - n * m_y * m_x\n",
    "    ss_xx = sum(x_known[i] * x_known[i] for i in range(n)) - n * m_x * m_x\n",
    "    b_1 = ss_xy / ss_xx\n",
    "    b_0 = m_y - b_1 * m_x\n",
    "\n",
    "    for i in missing_indices:\n",
    "        data[i] = b_0 + b_1 * i\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9965283a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch size for data processing\n",
    "batch_size = 20\n",
    "\n",
    "# Percentage of missingness in the data\n",
    "missingness_percentage = 20\n",
    "\n",
    "# Value of window_size and z_threshold for Moving Averages\n",
    "window_size = 5\n",
    "z_thresh = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0baf190f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: Daily_Sports_Activities_Sample.csv\n",
      "Execution time: 0.0 ms\n",
      "RMSE: 0.009433355050893173\n",
      "MAE: 0.004135354442344497\n",
      "==================================================\n",
      "Dataset: Gesture_Phase_Segmentation_Sample.csv\n",
      "Execution time: 0.0 ms\n",
      "RMSE: 0.04230114678288831\n",
      "MAE: 0.014937797821165466\n",
      "==================================================\n",
      "Dataset: Iris_Flowers_Sample.csv\n",
      "Execution time: 0.0 ms\n",
      "RMSE: 0.22432329046202218\n",
      "MAE: 0.0865164395549444\n",
      "==================================================\n",
      "Dataset: Mammographic_Mass_Sample.csv\n",
      "Execution time: 0.0 ms\n",
      "RMSE: 0.28062199513678887\n",
      "MAE: 0.11770895971136504\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Path to the folder containing datasets\n",
    "dataset_folder = \"./Datasets_Sample\"\n",
    "\n",
    "# Loop through all files in the folder\n",
    "for filename in os.listdir(dataset_folder):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        dataset_path = os.path.join(dataset_folder, filename)\n",
    "\n",
    "        # Load data from CSV using your custom function with specified batch size\n",
    "        original_data = read_csv(dataset_path, batch_size)\n",
    "        \n",
    "        # Measure the start time for execution time calculation\n",
    "        start_time = time.monotonic()\n",
    "        \n",
    "        # Detect outliers using Moving Averages and the specified variables\n",
    "        outliers = detect_outliers(original_data, window_size, z_thresh)\n",
    "        \n",
    "        # Introduce missingness into the data with specified missingness percentage\n",
    "        raw_data = introduce_missingness(original_data[:], missingness_percentage)\n",
    "        data = [float(item) for item in raw_data]\n",
    "        \n",
    "        # Perform SLR imputation\n",
    "        imputed_data = SLR_impute(data)\n",
    "        \n",
    "        # Measure the end time for execution time calculation\n",
    "        end_time = time.monotonic()\n",
    "\n",
    "        # Calculate elapsed time in milliseconds\n",
    "        elapsed_time_seconds = end_time - start_time\n",
    "        elapsed_time_ms = elapsed_time_seconds * 1000\n",
    "\n",
    "        # Calculate RMSE and MAE between original and imputed data\n",
    "        rmse = calculate_rmse(original_data, imputed_data)\n",
    "        mae = calculate_mae(original_data, imputed_data)\n",
    "\n",
    "        # Print the results for the current dataset\n",
    "        print(f'Dataset: {filename}')\n",
    "        print(f'Execution time: {elapsed_time_ms} ms')\n",
    "        print(f'RMSE: {rmse}')\n",
    "        print(f'MAE: {mae}')\n",
    "        print(\"=\" * 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
